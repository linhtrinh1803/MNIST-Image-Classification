# MNIST Image Classification

The original MNIST image dataset of handwritten digits is an useful baseline for image-based machine learning methods, moreover, experts are working to upgrade it and build drop-in replacements that are more difficult for computer vision and original for real-world applications.The Sign Language MNIST is offered here to encourage the community to produce more drop-in replacements. It uses the same CSV format as the other MNISTs, with labels and pixel values in single rows. With 24 classes of letters, the American Sign Language letter database of hand gestures is a multi-class problem (excluding J and Z which require motion)

The dataset format is designed to closely resemble the old MNIST format. Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (due to gesture motions, there are no cases for 9=J or 25=Z). The training data (27,455 cases) and test data (7172 cases) are about half the size of the regular MNIST, but they are generally identical, with the exception of a header row of labels, pixel1, pixel2, .. pixel784 which represent a single 28x28 pixel image with grayscale values between 0-255. Multiple users repeating the move against various backgrounds were represented in the original hand gesture image data.
